# Проект 1. Анализ вакансий на hh.ru


## Оглавление
[1. Описание проекта](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Описание-проекта)

[2. Какой кейс решаем?](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Какой-кейс-решаем)

[3. Требования к оформлению ноутбука](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Требования-к-оформлению-ноутбука)

[4. Что практикуем](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Что-практикуем)

[5. Краткая информация о данных](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Краткая-информация-о-данных)

[4. Этапы работы над проектом](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Этапы-работы-над-проектом)

[5. Результат](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Результат)

[6. Выводы](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Выводы)

## Описание проекта

В нашем распоряжении база резюме, выгруженная с сайта поиска вакансий hh.ru.

Файл с исходными данными вы можете скачать [здесь](https://drive.google.com/file/d/1Kb78mAWYKcYlellTGhIjPI-bCcKbGuTn/view?usp=sharing)(csv - 434Mb) или [здесь](https://drive.google.com/file/d/1-28hY8xmR2_6o-y6BWn6dZ9B0QAobqHG/view?usp=sharing)(zip - 62Mb).
Выгрузку курсов валют, которые встречаются в наших данных за период с 29.12.2017 по 05.12.2019: скачать её вы можете [здесь](https://lms.skillfactory.ru/assets/courseware/v1/15abf80f45a2f3e93c3274101b451c67/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/ExchangeRates.zip)(zip - 26Kb) или [здесь](https://drive.google.com/file/d/1lZB30qOpIk41eyLXqTc60p07SqhQTV4p/view?usp=sharing)(zip - 26Kb).

:arrow_up:[ к оглавлению](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Оглавление)

## Какой кейс решаем?
Проблематика: часть соискателей не указывает желаемую заработную плату, когда составляет своё резюме.

Чем это плохо?
⭐ Компания HeadHunter хочет построить модель, которая бы автоматически определяла примерный уровень заработной платы, подходящей пользователю, исходя из информации, которую он указал о себе. Но, как вы знаете, прежде чем построить модель, данные необходимо преобразовать, исследовать и очистить. В этом и состоит задача!

## Требования к оформлению ноутбука

- Решение оформляется только в Jupyter Notebook.
- Решение оформляется в соответствии с [ноутбуком-шаблоном](https://lms.skillfactory.ru/assets/courseware/v1/619ae706e569851b2a47820a175b212a/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/Ноутбук-шаблон_Project_1.ipynb).
- Каждое задание выполняется в отдельной ячейке, выделенной под задание.
- Код для каждого задания оформляется в одной-двух jupyter-ячейках.
- Решение должно использовать только пройденный материал: переменные, основные структуры данных (списки, словари, множества), циклы, функции, библиотеки numpy, pandas, matplotlib, seaborn, plotly. Все задания решаются с помощью уже знакомых методов.
- Код должен быть читаемым и понятным: имена переменных и функций отражают их сущность, важно избегать многострочных конструкций и условий.
- Пользуемся руководством PEP 8.
- Графики оформляются в соответствии с теми правилами, которые мы приводили в модуле по визуализации данных.
- Обязательное требование: графики должны содержать название, отражающее их суть, и подписи осей.
- Выводы к графикам оформляются в формате Markdown под самим графиком в отдельной ячейке. Выводы должны быть представлены в виде небольших связанных предложений на русском языке.

## Что практикуем
- Учимся исследовать структуры данных.
- Учимся преобразовывать данные.
- Учимся визуализировать данные.
- Учимся исследовать зависимости в данных

## Краткая информация о данных

|class 'pandas.core.frame.DataFrame'|

|RangeIndex: 44744 entries, 0 to 44743|

|Data columns (total 12 columns):|

    Column                           Non-Null Count  Dtype |

---  ------                           --------------  -----|

|0---Пол, возраст---------------------44744 non-null  object|
|
|1---ЗП-------------------------------44744 non-null  object
|
|2---Ищет работу на должность:--------44744 non-null  object
|
|3---Город, переезд, командировки-----44744 non-null  object
|
|4---Занятость------------------------44744 non-null  object
|
|5---График---------------------------44744 non-null  object
|
|6---Опыт работы----------------------44576 non-null  object
|
|7---Последнее/нынешнее место работы--44743 non-null  object
|
|8---Последняя/нынешняя должность-----44742 non-null  object
|
|9---Образование и ВУЗ----------------44744 non-null  object
|
|10--Обновление резюме----------------44744 non-null  object
|
|11--Авто-----------------------------44744 non-null  object
|
|dtypes: object(12)
|
|memory usage: 4.1+ MB

:arrow_up:[ к оглавлению](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Оглавление)

## Этапы работы над проектом

Наш проект будет состоять из четырёх частей:

1. Базовый анализ структуры данных

2. Преобразование данных

3. Разведывательный анализ

4. Очистка данных

Каждая часть будет состоять из блока практических заданий, которые необходимо выполнить в jupyter-ноутбуке, и контрольных вопросов на платформе, отвечая на которые можно проверить верность своего решения. Задания выполняются последовательно.

**1 базовый анализ структуры данных**

Начинаем мы, конечно же, со знакомства с данными и исследования их структуры. Нам важно понять, как устроены признаки в данных и какие типы они имеют, чтобы произвести дальнейшие преобразования.

**2 преобразование данных**

Теперь, когда мы познакомились с информацией в таблице, настало время самого сложного этапа — предобработки данных. В процессе знакомства с данными стало понятно что наши данные очень «сырые»: признаки представлены в неудобном для анализа и очистки формате. Например, столбец «Пол/возраст» содержит информацию и о поле, и о возрасте, и о дате рождения. Желаемая заработная плата представлена в виде текста с указанием валюты, в которой она исчисляется, и так далее…
Всё это не позволяет нам визуально оценить зависимости в данных: построить гистограмму распределения зарплаты и возраста, столбчатую диаграмму зарплаты по уровню образования и многое другое. Более того, мы не можем в таком виде заполнить пропущенные значения числовыми константами или найти выбросы. Иными словами, нам необходимо преобразовать данные, что позволит грамотно работать с ними.

**3 разведывательный анализ**

Теперь у нас есть всё необходимое, чтобы провести первичный анализ зависимостей в наших данных о резюме. Такой анализ часто называют разведывательным анализом (EDA) и он предназначен для выявления связей между признаками, выявления закономерностей, определения распределений признаков, поиска аномалий и других дефектов данных.

**4 очистка данных**

Когда мы проводили визуальный анализ, мы нашли несколько несостыковок в данных: пропуски, гигантские размеры желаемых заработных плат, резюме людей слишком «преклонного» возраста, опыт работы, превышающий возраст.

Всё это говорит о том, что данные подлежат очистке.

:arrow_up:[ к оглавлению](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Оглавление)

## Результат
В результате проделанной работы получили DataFrame очищенный от пропусков и аномалий.

:arrow_up:[ к оглавлению](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Оглавление)

## Выводы
Работая с сырыми данными, требуется соблюдать последовательность действий. На каждом этапе необходимо очень внимательно и кропотливо обращаться с данными. Особое внимание уделить возможным ошибкам на 2-м этапе т. к. даже небольшая ошибка может привести либо искажению, либо к потере данных. Хотя тоже можно сказать и о 3-м, 4-м этапах. Конечно, 1-й этап тоже важен, т. к. требуется тщательный анализ структуры данных, без которого невозможен успех на 2-м этапе.

:arrow_up:[ к оглавлению](https://github.com/KirillJbt/sf_data_science/blob/main/project_1/README.md#Оглавление)